from pathlib import Path

import torch
import torch.nn as nn
from torch import Tensor

from lightning.pytorch import LightningModule

from noposplat.model.encoder import get_encoder, EncoderCfg
from noposplat.model.types import Gaussians

from gspipline.renderer.gaussian_splatting_render import GaussianSplattingRender, GaussianSplattingConfig
from gspipline.pipeline.pipeline_mixins import LogMixin

from dataclasses import dataclass, field


@dataclass
class ImageEncoderConfig:
    repo_or_dir: str = 'facebookresearch/dinov2'
    """rep or dir"""
    model: str = "dinov2_vitg14"
    """model"""
    image_size: int | tuple[int, int] = 224
    """image size for the encoder"""

@dataclass
class DiscriminatorHeadConfig:
    ...

@dataclass
class LearningConfig:
    """learning rate"""
    base_lr: float = 0.0001
    """base learning rate"""
    encoder_lr_mult: float = 1.0
    """encoder learning rate multiplier"""
    head_lr_mult: float = 1.0
    """head learning rate multiplier"""
    encoder_trainable: bool = False
    """whether to train the encoder"""
    patience: int = 10
    """patience for early stopping"""
    factor: float = 0.1
    """factor for early stopping"""
    min_lr: float = 1e-6
    """minimum learning rate`"""
    monitor: str = "loss"
    """monitor for early stopping"""

@dataclass
class GaussianDiscriminatorPipelineConfig:
    gaussian_encoder: EncoderCfg = field(default_factory=EncoderCfg)
    """ encoder config """
    renderer: GaussianSplattingConfig = field(default_factory=GaussianSplattingConfig)
    """ renderer config """
    image_encoder: ImageEncoderConfig = field(default_factory=ImageEncoderConfig)
    """ image encoder config """
    discriminator_head: DiscriminatorHeadConfig = field(default_factory=DiscriminatorHeadConfig)
    """ discriminator head config """
    learning: LearningConfig = field(default_factory=LearningConfig)
    """ learning rate config """
    gaussian_size: int = 256
    """ size of the gaussian splatting grid """
    nomalize_intrinsics: bool = True
    """ whether to normalize the intrinsics """
    render_reference_view: bool = True
    """ whether to render reference view """
    render_novel_view: bool = True
    """ whether to render novel views """

class GaussianDiscriminatorPipeline(LightningModule, LogMixin):
    """ 
    Pipeline for training a discriminator to distinguish between real and fake images generated by the GaussianSplattingRender.
    The discriminator takes the rendered image and the features extracted from the image encoder as input, and outputs a probability of the image being real.
    """
    config: GaussianDiscriminatorPipelineConfig
    
    def __init__(self, config: GaussianDiscriminatorPipelineConfig):
        """
        Args:
            config (GaussianDiscriminatorPipelineConfig): configuration for the pipeline
        """
        if isinstance(config.image_encoder.image_size, int):
            config.image_encoder.image_size = (config.image_encoder.image_size, config.image_encoder.image_size)
        super().__init__()
        self.config = config
        self._init_loss()
        self._init_gaussian_encoder()
        self._init_renderer()
        self._init_discriminator()

    def _init_loss(self):
        self.bce_loss = nn.BCEWithLogitsLoss()

    def _init_gaussian_encoder(self):
        self.gaussian_encoder, _ = get_encoder(self.config.gaussian_encoder)
        state_dict = torch.load(self.config.gaussian_encoder.pretrained_weights)['state_dict']
        state_dict = {k[len("encoder."):] : v for k, v in state_dict.items() if k.startswith("encoder.")}
        self.gaussian_encoder.load_state_dict(state_dict)
        self.gaussian_encoder.eval()
        self.gaussian_encoder.requires_grad_(False)
    
    def _init_renderer(self):
        self.renderer = GaussianSplattingRender(self.config.renderer)
        self.renderer.eval()
        self.renderer.requires_grad_(False)

    def _init_discriminator(self):
        self.image_encoder: nn.Module = torch.hub.load(self.config.image_encoder.repo_or_dir, self.config.image_encoder.model)
        if not self.config.learning.encoder_trainable:
            self.image_encoder.eval()
            self.image_encoder.requires_grad_(False)

        self.head = nn.Sequential(
            nn.Linear(self._get_image_encoder_features_dim(), 512),
            nn.ReLU(True),
            nn.Linear(512, 1)
        )

    def _get_image_encoder_features_dim(self):
        return self.image_encoder.norm.weight.shape[0]
    
    def _predict_gaussian(self, image: Tensor, intrinsics: Tensor) -> Gaussians:
        """
            Args:
                batch (dict): a batch of data, containing:
                    - "image" (torch.Tensor): refence image, shape (B, v, 3, H, W)
                    - "mask" (torch.Tensor): optional, mask for refence image, shape (B, v, 1, H, W)
                    - "extrinsics" (torch.Tensor): optional, extrinsics for refence image, shape (B, v, 4, 4), nerfstudio coordinate system
                    - "intrinsics" (torch.Tensor): intrinsics for refence image, shape (B, v, 3, 3), fx, fy, cx, cy in normalized coordinates
            Returns:
                dict: a dictionary containing the predicted gaussian parameters, including:
                    - "means" (torch.Tensor): shape (B, HW, 3)
                    - "covariances" (torch.Tensor): shape (B, HW, 3, 3)
                    - "harmonics" (torch.Tensor): shape (B, HW, k, 3)
                    - "opacities" (torch.Tensor): shape (B, HW, k)
                    - "scales" (torch.Tensor): shape (B, HW)
                    - "rotations" (torch.Tensor): shape (B, HW, 4)
                    - "depth" (torch.Tensor): shape (B, HW)
        """
        if self.config.nomalize_intrinsics:
            H, W = image.shape[-2:]
            intrinsics = intrinsics.clone()
            intrinsics[:, :, 0, 0] /= W
            intrinsics[:, :, 1, 1] /= H
            intrinsics[:, :, 0, 2] /= W
            intrinsics[:, :, 1, 2] /= H

        # predict gaussian
        visualization_dump = {}
        gaussian: Gaussians = self.gaussian_encoder(
            context = {
                "image": image,
                "intrinsics": intrinsics,
            },
            global_step = 0, # TODO: use self.global_step
            visualization_dump = visualization_dump,
        )

        return {
            'means': gaussian.means,
            'covariances': gaussian.covariances,
            'colors': gaussian.harmonics.permute(0, 1, 3, 2),
            'opacities': gaussian.opacities,
            'quats': visualization_dump['rotations'],
            'scales': visualization_dump["scales"],
            'depth': visualization_dump["depth"],
        }

    def _render_gaussian(self, gaussians: dict, camtoworlds: Tensor, Ks: Tensor, width: int, height: int) -> dict:
        """
            Args:
                gaussians (dict): a dictionary containing the predicted gaussian parameters, including:
                    - "means" (torch.Tensor): shape (B, HW, 3)
                    - "quats" (torch.Tensor): shape (B, HW, 4)
                    - "scales" (torch.Tensor): shape (B, HW)
                    - "colors" (torch.Tensor): shape (B, HW, K, 3)
                camtoworlds (torch.Tensor): shape (B, n, 4, 4), nerfstudio coordinate system
                Ks (torch.Tensor): shape (B, n, 3, 3), fx, fy, cx, cy in normalized coordinates
                width (int): width of the rendered image
                height (int): height of the rendered image
            Returns:
                dict: a dictionary containing the rendered image, including:
                    - "image" (torch.Tensor): shape (B, n, H, W, 3)
                    - "mask" (torch.Tensor): shape (B, n, H, W)
                    - "depth" (torch.Tensor): shape (B, n, H, W)
        """
        B: int = gaussians['means'].shape[0]
        images = []
        masks = []
        for i in range(B):
            render_colors, render_alphas, info = self.renderer(
                    means=gaussians['means'][i],
                    quats=gaussians['quats'][i],
                    scales=gaussians['scales'][i],
                    opacities=gaussians['opacities'][i],
                    colors=gaussians['colors'][i],
                    camtoworlds=camtoworlds[i],
                    Ks=Ks[i],
                    width=width,
                    height=height,
                    need_active=False,
                )
            images.append(render_colors)
            masks.append(render_alphas)
        return {
            "image": torch.stack(images, dim=0),
            "mask": torch.stack(masks, dim=0),
        }
    
    def forward(self, images: Tensor, masks: Tensor = None) -> dict:
        """
            Args:
                images (torch.Tensor): shape (B, 3, H, W)
                masks (torch.Tensor): optional, shape (B, 1, H, W)
            Returns:
                dict: a dictionary containing the predicted probability of the image being real, and the features extracted from the image encoder.
                    - "pred" (torch.Tensor): shape (B, 1)
                    - "feature" (torch.Tensor): shape (B, D)
        """
        with torch.set_grad_enabled(self.config.learning.encoder_trainable and self.training):
            features: Tensor = self.image_encoder(images, masks)

        pred: Tensor = self.head(features)
        # pred = torch.sigmoid(pred)

        return {
            "pred": pred,
            "feature": features,
        }
    
    def _get_loss(self, preds: dict, targets: dict) -> dict:
        """
            Args:
                preds (dict): a dictionary containing the predicted probability of the image being real, and the features extracted from the image encoder.
                    - "pred" (torch.Tensor): shape (B, 1)
                    - "features" (torch.Tensor): shape (B, D)
                targets (dict): a dictionary containing the target information, including:
                    - "gt" (torch.Tensor): shape (B, 1)
            Returns:
                dict: a dictionary containing the loss and the output of the model.
                    - "bce_loss" (torch.Tensor): binary cross entropy loss
                    - "loss" (torch.Tensor): total loss
        """
        loss = 0
        bce_loss = self.bce_loss(preds["pred"], targets["gt"])
        loss += bce_loss
        return {
            "bce_loss": bce_loss,
            "loss": loss
        }

    def training_step(self, batch: dict, batch_idx: int, dataloader_idx: int = 0):
        """
            Args:
                batch (dict): a batch of data, containing
                    - "image" (torch.Tensor): refence image, shape (B, v, 3, H, W)
                    - "mask" (torch.Tensor): optional, mask for refence image, shape (B, v, 1, H, W)
                    - "extrinsics" (torch.Tensor): optional, extrinsics for refence image, shape (B, 4, 4), nerfstudio coordinate system
                    - "intrinsics" (torch.Tensor): optional, intrinsics for refence image, shape (B, 3, 3), fx, fy, cx, cy in normalized coordinates
                    - "novel_image" (torch.Tensor): optional, novel image, shape (B, n, 3, H, W)
                    - "novel_mask" (torch.Tensor): optional, mask for novel image, shape (B, n, 1, H, W)
                    - "novel_extrinsics" (torch.Tensor): pose for novel image, shape (B, n, 4, 4), nerfstudio coordinate system
                    - "novel_intrinsics" (torch.Tensor): intrinsics for novel image, shape (B, n, 3, 3), fx, fy, cx, cy in normalized coordinates
                Returns:
                    dict: a dictionary containing the loss and the output of the model.
        """
        image = batch['image'] * 2 - 1 # (B, v, 3, H, W)
        intrinsics = batch['intrinsics'] # (B, v, 3, 3)
        # predict gaussians        
        with torch.no_grad():
            gaussians = self._predict_gaussian(image, intrinsics)

        camtoworlds = []
        Ks = []
        if self.config.render_reference_view:
            camtoworlds.append(batch['extrinsics'])
            Ks.append(batch['intrinsics'])
        if self.config.render_novel_view:
            camtoworlds.append(batch['novel_extrinsics'])
            Ks.append(batch['novel_intrinsics'])
        camtoworlds = torch.cat(camtoworlds, dim=1)
        Ks = torch.cat(Ks, dim=1)
        width = batch['width'][0]
        height = batch['height'][0]
        with torch.no_grad():
            renderings = self._render_gaussian(gaussians, camtoworlds, Ks, width, height)

        fake_images: Tensor = renderings['image'] # (B, n, H, W, 3)
        fake_images = fake_images.flatten(0, 1) # (Bn, H, W, 3)
        fake_images = fake_images.permute(0, 3, 1, 2) # (Bn, 3, H, W)
        real_images: Tensor = batch['image'] # (B, v, 3, H, W)
        real_images = real_images.flatten(0, 1) # (Bv, 3, H, W)
        images = torch.cat([real_images, fake_images], dim=0) # (Bv+Bn, 3, H, W)
        if self.config.image_encoder.image_size[0] != images.shape[-1] or self.config.image_encoder.image_size[1] != images.shape[-2]:
            images = nn.functional.interpolate(images, size=self.config.image_encoder.image_size, mode='bilinear', align_corners=False)

        preds = self(images)

        gt = torch.cat([torch.ones(real_images.shape[0], 1), torch.zeros(fake_images.shape[0], 1)], dim=0).to(self.device) # (Bv+Bn, 1)
        targets = {
            "gt": gt,
        }
        losses = self._get_loss(preds, targets=targets)

        self.log_loss(losses)

        return {
            "loss": losses["loss"],
            # "images": images,
        }

    def configure_optimizers(self) -> torch.optim.Optimizer:
        """
            Returns:
                torch.optim.Optimizer: optimizer for the model
        """
        params = []
        params.append({"params": self.head.parameters(), "lr": self.config.learning.base_lr * self.config.learning.head_lr_mult})
        if self.config.learning.encoder_trainable:
            params.append({"params": self.image_encoder.parameters(), "lr": self.config.learning.base_lr * self.config.learning.encoder_lr_mult})
        optimizer = torch.optim.Adam(params)
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=self.config.learning.patience, factor=self.config.learning.factor, min_lr=self.config.learning.min_lr)
        return {
            "optimizer": optimizer,
            "lr_scheduler": scheduler,
            "monitor": self.config.learning.monitor,
        }